{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the necessary Libraries"
      ],
      "metadata": {
        "id": "8QQKeGkf9j_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky081Jozzkym"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***In this Project, we are using the TensorFlow Framework***."
      ],
      "metadata": {
        "id": "h2h-P-C0Ae7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The provided code defines a class named **traffic_sign_classifier** that encapsulates functionalities related to traffic sign classification using **Convolutional Neural Networks (CNNs).**\n",
        "\n",
        "\n",
        "1. ***Initialization***: The constructor __init__ loads data from a pickle file (data0.pickle) containing training, validation, and test datasets for images of traffic signs. It organizes the data into attributes like x_train, y_train, x_valid, y_valid, x_test, y_test, and labels.\n",
        "2.  ***Data Exploration***: The method print_shape prints the shape of different datasets, providing insight into the dimensions of the image data.\n",
        "3. ***Visualization***: The method plot_grid plots a grid of images with their corresponding labels. It randomly selects images from the training dataset and displays them in a grid format.\n",
        "4. ***Preprocessing***: The method gray_normalization performs data preprocessing steps. It shuffles the training dataset, converts the images to grayscale, and then normalizes the pixel values to fall within the range [-1, 1].\n",
        "5. ***Model Definition***: The method build_CNN_model constructs a CNN model using the Keras Sequential API. It defines layers for convolution, max-pooling, dropout, flattening, and dense (fully connected) layers, ending with a softmax layer for multi-class classification.\n",
        "6. ***Model Management***: The methods save_model and load_model_data handle saving and loading trained models using Keras.\n",
        "7. ***Model Training***: The method compile_and_train compiles the CNN model with specified optimizer, loss function, and metrics. It then trains the model on the preprocessed training data for a specified number of epochs while validating on a separate validation dataset.\n",
        "8. ***Model Training***: The method compile_and_train compiles the CNN model with specified optimizer, loss function, and metrics. It then trains the model on the preprocessed training data for a specified number of epochs while validating on a separate validation dataset.\n",
        "9. ***Training Visualization***: The method plot_metrics visualizes the training and validation accuracy and loss over epochs using matplotlib.\n",
        "10. ***Model Evaluation***: The method evaluate_model evaluates the trained model's performance on the test dataset and prints the evaluation metrics (typically accuracy and loss).\n",
        "11. ***Testing***: The method test_plot performs inference on a subset of the test dataset and plots the original images alongside their predicted classes. This helps in visually assessing the model's performance on unseen data.\n",
        "\n",
        " # **Overall, this class provides a comprehensive framework for traffic sign classification, covering data loading, preprocessing, model construction, training, evaluation, and visualization.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nuz6GB_Q-C48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class traffic_sign_classifier():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        with open('data0.pickle', 'rb') as file1:\n",
        "            data = pickle.load(file1, encoding='latin1')\n",
        "\n",
        "        #load data--------------------------------\n",
        "        self.x_train = data['x_train'].transpose(0,2,3,1)\n",
        "        self.y_train = data['y_train']\n",
        "        self.x_valid = data['x_validation'].transpose(0,2,3,1)\n",
        "        self.y_valid = data['y_validation']\n",
        "        self.x_test = data['x_test'].transpose(0,2,3,1)\n",
        "        self.y_test = data['y_test']\n",
        "        self.labels = data['labels']\n",
        "    #------------------------------------------\n",
        "\n",
        "    def print_shape(self):\n",
        "        print('x_train: {}'.format(self.x_train.shape))\n",
        "        print('y_train: {}'.format(self.y_train.shape))\n",
        "        print('x_valid: {}'.format(self.x_valid.shape))\n",
        "        print('y_valid: {}'.format(self.y_valid.shape))\n",
        "        print('x_test: {}'.format(self.x_test.shape))\n",
        "        print('y_test: {}'.format(self.y_test.shape))\n",
        "\n",
        "    def plot_grid(self, l_grid, w_grid):\n",
        "\n",
        "        #plotting images and labels in a grid of 5 x 5:\n",
        "        l_grid = 5\n",
        "        w_grid = 5\n",
        "        _, axes = plt.subplots(l_grid, w_grid, figsize = (10,10))\n",
        "        axes = axes.ravel()\n",
        "        for i in np.arange(0, l_grid * w_grid):\n",
        "            j = np.random.randint(i, len(self.x_train))\n",
        "            axes[i].imshow(self.x_train[j])\n",
        "            axes[i].set_title(self.labels[self.y_train[j]], fontsize = 10)\n",
        "            axes[i].axis('off')\n",
        "        plt.subplots_adjust(hspace=0.5)\n",
        "        plt.show()\n",
        "\n",
        "    def gray_normalization(self):\n",
        "        #shuffling datasets to prevent the NN to learn any possible sequence:\n",
        "        self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
        "        #grayscale_conversion:\n",
        "        self.x_train_gray_norm = np.sum(self.x_train/3, axis = 3, keepdims=True)\n",
        "        self.x_valid_gray_norm = np.sum(self.x_valid/3, axis = 3, keepdims=True)\n",
        "        self.x_test_gray_norm = np.sum(self.x_test/3, axis = 3, keepdims=True)\n",
        "\n",
        "        #normalization:-\n",
        "        self.x_train_gray_norm = (self.x_train_gray_norm - 128) / 128\n",
        "        self.x_valid_gray_norm = (self.x_valid_gray_norm - 128) / 128\n",
        "        self.x_test_gray_norm = (self.x_test_gray_norm - 128) / 128\n",
        "\n",
        "        #print('x_train_gray_norm: {}'.format(self.x_train_gray_norm.shape))\n",
        "        #print('x_valid_gray_norm: {}'.format(self.x_valid_gray_norm.shape))\n",
        "        #print('x_test_gray_norm: {}'.format(self.x_test_gray_norm.shape))\n",
        "\n",
        "    def build_CNN_model(self, dropout = 0.2):\n",
        "        self.CNN = Sequential([\n",
        "            Conv2D(16, (3,3), padding = 'same', activation='relu', input_shape = (32,32,1)),\n",
        "            MaxPooling2D((2,2)),\n",
        "            Conv2D(32, (3,3), padding = 'same', activation='relu'),\n",
        "            MaxPooling2D(2,2),\n",
        "            Dropout(dropout),\n",
        "            Conv2D(64, (3,3), activation='relu'),\n",
        "            MaxPooling2D((2,2)),\n",
        "            Flatten(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(86,activation='relu'),\n",
        "            Dense(43, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    def save_model(self, save_path):\n",
        "        self.CNN.save(save_path)\n",
        "\n",
        "    def load_model_data(self, load_path):\n",
        "        self.CNN = load_model(load_path)\n",
        "\n",
        "    def compile_and_train(self, lr=0.001):\n",
        "        self.CNN.compile(optimizer = Adam(learning_rate = lr), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "        self.history = self.CNN.fit(self.x_train_gray_norm, self.y_train, batch_size = 500, epochs = 100,\n",
        "                                    verbose = 3, validation_data = (self.x_valid_gray_norm, self.y_valid))\n",
        "        self.score = self.CNN.evaluate(self.x_test_gray_norm, self.y_test)\n",
        "\n",
        "    def plot_metrics(self):\n",
        "\n",
        "        accuracy = self.history.history['accuracy']\n",
        "        val_accuracy = self.history.history['val_accuracy']\n",
        "        loss = self.history.history['loss']\n",
        "        val_loss = self.history.history['val_loss']\n",
        "\n",
        "\n",
        "        epochs = range(len(accuracy))\n",
        "        plt.figure(1)\n",
        "        plt.plot(epochs, accuracy, 'r-', label = 'Training accuracy')\n",
        "        plt.plot(epochs, val_accuracy, 'b-', label = 'Validation accuracy')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(2)\n",
        "        plt.plot(epochs, loss, 'r-', label = 'Training loss')\n",
        "        plt.plot(epochs, val_loss, 'b-', label = 'Validation loss')\n",
        "        plt.title('Training and Validation loss')\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        score = self.CNN.evaluate(self.x_test_gray_norm, self.y_test, batch_size = 500)\n",
        "        print(score)\n",
        "\n",
        "    def test_plot(self):\n",
        "        predicted_classes = self.CNN.predict_classes(self.x_test_gray_norm)\n",
        "        l_grid = 2\n",
        "        w_grid = 2\n",
        "        _, axes = plt.subplots(l_grid, w_grid, figsize = (12,12))\n",
        "        axes = axes.ravel()\n",
        "        for i in np.arange(0, l_grid * w_grid):\n",
        "            #j = np.random.randint(i, len(self.x_test))\n",
        "            axes[i].imshow(self.x_test[i])\n",
        "            # axes[i].set_title(self.labels[self.y_test[j]], fontsize = 8)\n",
        "            print('Predicted_class: {} -- Label: {}'.format(predicted_classes[i], self.y_test[i]))\n",
        "            axes[i].axis('off')\n",
        "        plt.subplots_adjust(hspace=0.5)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "QANY8v9ez472"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here, you've created an instance of the **traffic_sign_classifier** class named tfsc and called the print_shape method to display the shapes of different datasets."
      ],
      "metadata": {
        "id": "LEHZGvoSAxNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt #  Imports the matplotlib library for data visualization and assigns it the alias plt.\n",
        "tfsc = traffic_sign_classifier() # Creates an instance of the traffic_sign_classifier class and assigns it to the variable tfsc\n",
        "import numpy as np\n",
        "tfsc.print_shape() # Calls the print_shape method of the tfsc object, which prints the shapes of different datasets."
      ],
      "metadata": {
        "id": "S3uMd6s60chv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The remaining lines of code are commented out and are not executed.\n",
        "# ***These method calls are essential for various stages of the machine learning workflow, including data preprocessing, model construction, training, evaluation, and visualization of results. Uncommenting and executing these lines would enable you to perform these tasks and analyze the performance of your traffic sign classifier model.***"
      ],
      "metadata": {
        "id": "PTMIg31BBhVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tfsc.plot_grid(5,5)\n",
        "# This method call likely plots a grid of images along with their corresponding labels. The parameters (5,5) indicate the dimensions of the grid.\n",
        "\n",
        "#tfsc.gray_normalization()\n",
        "# performs grayscale conversion and normalization on the datasets.\n",
        "# It shuffles the datasets to prevent the neural network from learning any sequence and then normalizes the datasets.\n",
        "\n",
        "#tfsc.build_CNN_model(dropout=0.4)\n",
        "# constructs a Convolutional Neural Network (CNN) model.\n",
        "#The parameter dropout=0.4 indicates the dropout rate, which is a regularization technique used to prevent overfitting.\n",
        "\n",
        "#accuracy =\n",
        "#tfsc.CNN.summary()\n",
        "#prints a summary of the CNN model, including information about the layers, parameters, and output shapes.\n",
        "\n",
        "#tfsc.load_model_data(load_path = 'model_dropout_4.h5')\n",
        "#loads a pre-trained model from the specified file path ('model_dropout_4.h5').\n",
        "\n",
        "#tfsc.compile_and_train()\n",
        "# compiles and trains the CNN model using the training dataset.\n",
        "#It specifies the optimizer, loss function, and metrics for training, as well as the number of epochs and batch size.\n",
        "\n",
        "#tfsc.test_plot()\n",
        "#plots a grid of images from the test dataset along with their predicted classes.\n",
        "#It helps visualize the performance of the trained model on unseen data.\n",
        "\n",
        "#tfsc.save_model(save_path = 'model_dropout_4.h5')\n",
        "# saves the trained model to the specified file path ('model_dropout_4.h5').\n",
        "\n",
        "#tfsc.plot_metrics()\n",
        "# plots the training and validation metrics (e.g., accuracy and loss) over epochs to visualize the training progress and model performance.\n",
        "\n",
        "#tfsc.evaluate_model()\n",
        "# evaluates the performance of the trained model on the test dataset and prints the evaluation score (e.g., accuracy)."
      ],
      "metadata": {
        "id": "jO8EDineBhzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}